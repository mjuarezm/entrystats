{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#Introduction\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></div><div class=\"lev2\"><a href=\"#Collected-data\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Collected data</a></div><div class=\"lev2\"><a href=\"#Collected-data\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Collected data</a></div><div class=\"lev2\"><a href=\"#Latency\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Latency</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The objective of this analysis is to study the distribution of network jitter in Tor entry guards. Some nodes might have a significantly large jitter than the average. We believe that in those cases, website fingerprinting may have lower effectiveness than in the entry guards with low jitter. The rationale is that even if the entry to guard TCP connection is independent of the website, the interaction between the page structure (HTTP request/response pattern) and the jitter, may make the fingerprint less reliable than in low-jitter guards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from os import listdir\n",
    "from os.path import join, dirname, realpath, isdir, getmtime\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.style.use('ggplot')\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "# Notebook config\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " document.title = 'Variance analysis';\n",
       " code_show = !code_show\n",
       " var divs = document.getElementsByClassName('input');\n",
       " var divs = document.getElementsByClassName('input');\n",
       " if (code_show){\n",
       "   for (var i in divs) {\n",
       "     if (typeof divs[i] != 'undefined') {\n",
       "       divs[i].style.display = 'block';\n",
       "     } \n",
       "   }\n",
       " } else {\n",
       "   for (var i in divs) {\n",
       "     if (typeof divs[i] != 'undefined') {\n",
       "       divs[i].style.display = 'none';\n",
       "     } \n",
       "   }\n",
       " }\n",
       "} \n",
       "\n",
       "document.addEventListener(\"DOMContentLoaded\", function(event) { \n",
       "  code_toggle()\n",
       "});\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# button to toggle code\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " document.title = 'Variance analysis';\n",
    " code_show = !code_show\n",
    " var divs = document.getElementsByClassName('input');\n",
    " var divs = document.getElementsByClassName('input');\n",
    " if (code_show){\n",
    "   for (var i in divs) {\n",
    "     if (typeof divs[i] != 'undefined') {\n",
    "       divs[i].style.display = 'block';\n",
    "     } \n",
    "   }\n",
    " } else {\n",
    "   for (var i in divs) {\n",
    "     if (typeof divs[i] != 'undefined') {\n",
    "       divs[i].style.display = 'none';\n",
    "     } \n",
    "   }\n",
    " }\n",
    "} \n",
    "\n",
    "document.addEventListener(\"DOMContentLoaded\", function(event) { \n",
    "  code_toggle()\n",
    "});\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mjuarezm/git/entrystats/results/170201_112253\n"
     ]
    }
   ],
   "source": [
    "# directories\n",
    "BASE_DIR = dirname(realpath(\"__file__\"))\n",
    "RESULTS_DIR = join(BASE_DIR, 'results')\n",
    "LATEST_DIR = max([join(RESULTS_DIR, d) for d in listdir(RESULTS_DIR)\n",
    "                  if isdir(join(RESULTS_DIR, d))], key=getmtime)\n",
    "print LATEST_DIR\n",
    "\n",
    "# globals\n",
    "CSV_NAMES = [\"ip_proto\", \"epoch\",\n",
    "             \"ip_src\", \"ip_dst\", \"port_src\", \"port_dst\",\n",
    "             \"ip_len\", \"ip_hdr_len\", \"tcp_hdr_len\", \"data_len\",\n",
    "             \"tcp_flags\", \"tcp_seq\", \"tcp_ack\", \"next_seq\", \"acks_frame\",\n",
    "             \"tcp_window_size_value\", \"ws_message\",\n",
    "             \"tcp_options_tsval\", \"tcp_options_tsecr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "dfs = []\n",
    "for fname in listdir(LATEST_DIR):\n",
    "    entry, sample = fname.split('_')\n",
    "    df = pd.read_csv(join(LATEST_DIR, fname), names=CSV_NAMES)\n",
    "    df['tcp_flags'] = df['tcp_flags'].apply(lambda s: int(s, 0))\n",
    "    df['entry'] = entry\n",
    "    df['sample'] = sample\n",
    "    dfs.append(df)\n",
    "data = pd.concat(dfs)\n",
    "\n",
    "entries = data.groupby(['entry']).count()\n",
    "num_entries = len(entries)\n",
    "avg_samples = entries.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collected data\n",
    "\n",
    "\n",
    "For our data collection, we make a TCP connection to the guard's OR port and record all the traffic that is generated. In total, we have collected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"- Data for\", num_entries, \"entry guards\"\n",
    "print \"- An average of\", int(avg_samples), \"samples for each entry guard.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "guards": "426",
     "int(avg_samples)": "1"
    }
   },
   "source": [
    "This is how the dataset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data in a dataframe\n",
    "dfs = []\n",
    "for k, l in stat_files.iteritems():\n",
    "    for i, fpath in enumerate(l):\n",
    "        df = pd.read_csv(fpath, names=CSV_NAMES)\n",
    "        df['tcp_flags'] = df['tcp_flags'].apply(lambda s: int(s, 0))\n",
    "        df['entry'] = k\n",
    "        df['sample'] = i\n",
    "        dfs.append(df)\n",
    "data = pd.concat(dfs)\n",
    "data[['entry', 'sample'] + [c for c in data.columns if c != 'entry' and c != 'sample']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency\n",
    "\n",
    "From the traffic traces collected for the TCP connections to the guards, we extract the first SYN+ACK packet (if any) and its corresponding SYN packet. Next, we substract the SYN timestamp to the SYN+ACK timestamp to obtain a measurement of the latency to a guard.\n",
    "\n",
    "This is the dataset of latencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def latency(d):\n",
    "    \"\"\"Return difference between first syn+ack and its corresponding syn.\"\"\"\n",
    "    syn_acks = d[(np.isnan(d['data_len'])) & (d['tcp_flags'] == 18)]\n",
    "    if len(syn_acks) == 0:\n",
    "        return np.nan\n",
    "    syn_ack = syn_acks.head(1).iloc[0]\n",
    "    syn_seq = syn_ack['tcp_ack'] - 1\n",
    "    syns = d[(d['tcp_flags'] == 2) & (d['tcp_seq'] == syn_seq)]\n",
    "    if len(syns) == 0:\n",
    "        return np.nan\n",
    "    syn = syns.head(1).iloc[0]\n",
    "    return syn_ack['epoch'] - syn['epoch']\n",
    "    \n",
    "def latencies(data):\n",
    "    \"\"\"Compute latencies for all samples in the dataframe.\"\"\"\n",
    "    return data.groupby(['entry', 'sample']).apply(latency).reset_index(name='latency')\n",
    "\n",
    "\n",
    "def jitter(latencies):\n",
    "    \"\"\"Compute jitter from latency data.\"\"\"\n",
    "    return latencies.groupby(['entry'])['latency'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lats = latencies(data).dropna()\n",
    "lats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We extract some basic statistics about the latencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We plot the histogram of latencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)\n",
    "lats['latency'].plot(kind='hist', bins=20, ax=ax1, figsize=(10, 3), title=\"Entry latency\")\n",
    "lats['latency'].apply(np.log).plot(kind='hist', bins=20, ax=ax2, figsize=(10, 3), title=\"Entry altency (log scale)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Jitter\n",
    "\n",
    "We measure jitter of a node as the variance of the node's latency. We can calculate the variance because we take several samples for each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jitter(lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "toc_cell": true,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
